import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader, TensorDataset
import json
import joblib
import os
import re
from tqdm import tqdm
from deepctr_torch.inputs import (
    SparseFeat,
    DenseFeat,
    get_feature_names,
    # build_input_features, # ä¸è¦
    combined_dnn_input,
)
from deepctr_torch.models.basemodel import BaseModel
from deepctr_torch.layers import CrossNet, DNN

# from sklearn.preprocessing import StandardScaler # ä¸è¦
# from sklearn.cluster import KMeans # ä¸è¦
import gc

# import types # ä¸è¦
# import polars as pl # ä¸è¦
import torch.nn.functional as F

# from collections import defaultdict # ä¸è¦
import glob

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
PREPROCESSED_DATA_PATH = "preprocessed_lstm_data.npz"  # preprocess_sequences.py ã®å‡ºåŠ›
PREPROCESSOR_BASE_DIR = "lstm_preprocessor_score"  # ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ãƒ­ãƒ¼ãƒ‰ç”¨
MODEL_OUTPUT_DIR = "lstm_models_score"  # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ç”¨
OUTPUT_DIR = "evaluation_results_lstm"  # è©•ä¾¡çµæœã®å‡ºåŠ›å…ˆ

# --- ãƒ¢ãƒ‡ãƒ«æ§‹é€ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¨åˆã‚ã›ã‚‹) ---
EMBEDDING_DIM = 8
CROSS_NUM = 3
DNN_HIDDEN_UNITS = (256, 128)
N_STEPS = 5  # preprocessed_lstm_data.npz ã® N_STEPS ã¨ä¸€è‡´ã•ã›ã‚‹
LSTM_HIDDEN_SIZE = 64
LSTM_LAYERS = 1
LSTM_DROPOUT = 0.2
# CLUSTER_N = 6 # ä¸è¦
# RUN_CLUSTERING = True # ä¸è¦

# --- è©•ä¾¡ç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
BATCH_SIZE = 256
NUM_WORKERS = 0  # .npz ã‹ã‚‰ã®ãƒ­ãƒ¼ãƒ‰ã¯é«˜é€Ÿãªã®ã§ 0 ã§è‰¯ã„
TARGET_COL = "rank_score"  # npz ãƒ•ã‚¡ã‚¤ãƒ«å†…ã® 'y' ã«å¯¾å¿œ

# â–¼â–¼â–¼ã€ä¿®æ­£ã€‘å›åç‡è¨ˆç®—ã«ä½¿ã†åˆ—ã‚’ã€Œè¤‡å‹é…å½“ã€ã«çµ±ä¸€ â–¼â–¼â–¼
ODDS_COL = "è¤‡å‹åœå†…_å®Ÿ"  # è¤‡å‹ã®é…å½“é‡‘ãã®ã‚‚ã®ã‚’ä½¿ã†
WIN_FLAG_COL = "è¤‡å‹åœå†…_å®Ÿ"  # è¤‡å‹ã®é…å½“é‡‘ (0ã‚ˆã‚Šå¤§ãã‘ã‚Œã°çš„ä¸­)
# â–²â–²â–²ã€ä¿®æ­£ã“ã“ã¾ã§ã€‘â–²â–²â–²

RACE_ID_COL = "race_id"
HORSE_NAME_COL = "é¦¬å"

# â–¼â–¼â–¼ã€è¿½åŠ ã€‘NPZã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—ã®ãƒªã‚¹ãƒˆ â–¼â–¼â–¼
META_COLS_FOR_EVAL = [
    RACE_ID_COL,
    HORSE_NAME_COL,
    ODDS_COL,
    WIN_FLAG_COL,
    "æ—¥ä»˜",  # è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ç”¨
    "ç€é †",  # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦è¨ˆç®—ç”¨
    "é¦¬ç•ª",  # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ç²¾åº¦è¨ˆç®—ç”¨
    "å˜å‹",  # æˆ¦ç•¥è¨ˆç®—ç”¨
    "å˜å‹ã‚ªãƒƒã‚º",  # æˆ¦ç•¥è¨ˆç®—ç”¨
    # æ³¨æ„: preprocess_sequences.py ã® META_COLS_FOR_EVAL ã«ã‚‚ã“ã‚Œã‚‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
]
# â–²â–²â–²ã€è¿½åŠ ã“ã“ã¾ã§ã€‘â–²â–²â–²


# === LSTM Hybrid ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹å®šç¾© (ã“ã“ã‹ã‚‰) ===
# (keiba_analysis.py ã‹ã‚‰ DCN_LSTM_Hybrid ã‚¯ãƒ©ã‚¹å®šç¾©ã‚’ãã®ã¾ã¾ã‚³ãƒ”ãƒ¼)
# (å¤‰æ›´ãªã—ã€å†…å®¹ã¯çœç•¥)
class DCN_LSTM_Hybrid(BaseModel):
    def __init__(
        self,
        static_linear_feature_columns,
        static_dnn_feature_columns,
        sequence_feature_columns,
        # static_feature_names, # __init__ ã§ã¯ä¸è¦
        lstm_hidden_size=64,
        lstm_layers=1,
        lstm_dropout=0.2,
        cross_num=2,
        dnn_hidden_units=(256, 128),
        l2_reg_linear=0.00001,
        l2_reg_embedding=0.00001,
        l2_reg_cross=0.00001,
        l2_reg_dnn=0,
        init_std=0.0001,
        seed=1024,
        dnn_dropout=0,
        dnn_activation="relu",
        dnn_use_bn=False,
        task="regression",
        device="cpu",
        gpus=None,
    ):

        super(DCN_LSTM_Hybrid, self).__init__(
            linear_feature_columns=static_linear_feature_columns,
            dnn_feature_columns=static_dnn_feature_columns,
            l2_reg_linear=l2_reg_linear,
            l2_reg_embedding=l2_reg_embedding,
            init_std=init_std,
            seed=seed,
            task=task,
            device=device,
            gpus=gpus,
        )

        # self.static_feature_names = static_feature_names # ä¸è¦
        self.sequence_feature_columns = sequence_feature_columns
        self.static_linear_feature_columns = static_linear_feature_columns
        self.static_dnn_feature_columns = static_dnn_feature_columns
        # self.dnn_hidden_units = dnn_hidden_units # DNNå†…ã§ä½¿ã†ã®ã§ä¸è¦

        # --- LSTMéƒ¨åˆ† ---
        seq_sparse_feature_columns = [
            fc for fc in sequence_feature_columns if isinstance(fc, SparseFeat)
        ]
        seq_dense_feature_columns = [
            fc for fc in sequence_feature_columns if isinstance(fc, DenseFeat)
        ]

        # embedding_dict ãŒ super().__init__ ã§ä½œæˆã•ã‚Œã‚‹ã®ã‚’å¾…ã¤
        lstm_input_size = sum(
            self.embedding_dict[fc.embedding_name].embedding_dim
            for fc in seq_sparse_feature_columns
            if fc.embedding_name in self.embedding_dict
        ) + len(seq_dense_feature_columns)

        if lstm_input_size == 0:
            print(
                "è­¦å‘Š: LSTM input_size ãŒ 0 ã§ã™ã€‚ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç‰¹å¾´é‡ãŒæ­£ã—ãå®šç¾©ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            )
            # Fallback to a small dummy size to avoid LSTM error if no seq features
            lstm_input_size = 1  # Or handle appropriately

        self.lstm = nn.LSTM(
            input_size=lstm_input_size,
            hidden_size=lstm_hidden_size,
            num_layers=lstm_layers,
            batch_first=True,
            dropout=lstm_dropout if lstm_layers > 1 else 0,
        )

        # --- DCNéƒ¨åˆ† ---
        static_dnn_input_dim = self.compute_input_dim(static_dnn_feature_columns)
        # Handle case where static_dnn_input_dim might be 0
        self.dnn_input_dim = (
            static_dnn_input_dim + lstm_hidden_size
            if static_dnn_input_dim > 0
            else lstm_hidden_size
        )

        if self.dnn_input_dim == 0:
            print(
                "è­¦å‘Š: DNN input_dim ãŒ 0 ã§ã™ã€‚é™çš„ç‰¹å¾´é‡ã‚‚ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ç‰¹å¾´é‡ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚"
            )
            # Add dummy layers if input is zero? Or raise error?
            # For now, create DNN but it might fail in forward if input is truly zero
            self.dnn = nn.Identity()  # Placeholder
            self.dnn_linear = nn.Linear(
                lstm_hidden_size if lstm_hidden_size > 0 else 1, 1, bias=False
            ).to(device)
        else:
            self.dnn = DNN(
                self.dnn_input_dim,
                dnn_hidden_units,
                activation=dnn_activation,
                l2_reg=l2_reg_dnn,
                dropout_rate=dnn_dropout,
                use_bn=dnn_use_bn,
                init_std=init_std,
                device=device,
            )
            dnn_output_dim = (
                dnn_hidden_units[-1] if dnn_hidden_units else self.dnn_input_dim
            )
            self.dnn_linear = nn.Linear(dnn_output_dim, 1, bias=False).to(device)

        self.cross_input_dim = self.compute_input_dim(static_linear_feature_columns)
        if self.cross_input_dim > 0:
            self.crossnet = CrossNet(self.cross_input_dim, cross_num, device=device)
            self.cross_linear = nn.Linear(self.cross_input_dim, 1, bias=False).to(
                device
            )
        else:
            # Handle case where there are no linear features for CrossNet
            print("æƒ…å ±: CrossNet ã®å…¥åŠ›æ¬¡å…ƒãŒ 0 ã®ãŸã‚ã€CrossNet ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚")
            self.crossnet = None
            self.cross_linear = None

        # self.add_regularization_weight(self.embedding_dict, l2_reg_embedding) # BaseModelãŒã‚„ã‚‹ã¯ãš
        # self.add_regularization_weight(self.dnn.linears, l2_reg_dnn) # BaseModelãŒã‚„ã‚‹ã¯ãš
        # self.add_regularization_weight(self.crossnet.kernels, l2_reg_cross) # BaseModelãŒã‚„ã‚‹ã¯ãš? è¦ç¢ºèª
        # self.add_regularization_weight(self.linear.weight, l2_reg_linear) # BaseModelãŒã‚„ã‚‹ã¯ãš

        self.to(device)

    # (forwardãƒ¡ã‚½ãƒƒãƒ‰ã¯ keiba_analysis.py ã‹ã‚‰ã‚³ãƒ”ãƒ¼ã—ãŸã¾ã¾ã€å¤‰æ›´ãªã—)
    # (å†…å®¹ã¯çœç•¥)
    def forward(self, X_seq_tensor, X_static_tensor):
        batch_size = (
            X_static_tensor.shape[0]
            if X_static_tensor is not None and X_static_tensor.nelement() > 0
            else (
                X_seq_tensor.shape[0]
                if X_seq_tensor is not None and X_seq_tensor.nelement() > 0
                else 0
            )
        )
        if batch_size == 0:
            # Handle empty batch case
            return torch.zeros((0, 1)).to(self.device)

        # --- LSTMå…¥åŠ›ã®æº–å‚™ ---
        seq_sparse_embedding_list = []
        seq_dense_value_list = []
        current_seq_col_idx = 0
        # sequence_feature_columns ã®é †åºã§ãƒ«ãƒ¼ãƒ—ã—ã€ãƒ†ãƒ³ã‚½ãƒ«åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        seq_feat_map = {
            fc.name: i for i, fc in enumerate(self.sequence_feature_columns)
        }

        if X_seq_tensor is not None and X_seq_tensor.nelement() > 0:
            for fc in self.sequence_feature_columns:
                try:
                    current_seq_col_idx = seq_feat_map[fc.name]
                    if current_seq_col_idx >= X_seq_tensor.shape[2]:  # Check bounds
                        # print(f"è­¦å‘Š: Seq tensor index out of bounds for {fc.name} (idx {current_seq_col_idx}). Skipping.")
                        continue
                except KeyError:
                    # print(f"è­¦å‘Š: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ãƒ†ãƒ³ã‚½ãƒ«å†…ã«ç‰¹å¾´é‡ {fc.name} ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue

                if isinstance(fc, SparseFeat):
                    if fc.embedding_name in self.embedding_dict:
                        embedding_layer = self.embedding_dict[fc.embedding_name]
                        try:
                            ids = X_seq_tensor[:, :, current_seq_col_idx].long()
                            emb = embedding_layer(ids)
                            seq_sparse_embedding_list.append(emb)
                        except IndexError as e:
                            print(
                                f"IndexError seq sparse forward: {fc.name}, idx:{current_seq_col_idx}, shape:{X_seq_tensor.shape}"
                            )
                            raise e
                        except Exception as e:
                            print(f"Error seq sparse forward: {fc.name}")
                            raise e
                    # else: print(f"è­¦å‘Š: Seq EmbãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {fc.embedding_name}")
                elif isinstance(fc, DenseFeat):
                    try:
                        val = X_seq_tensor[:, :, current_seq_col_idx].unsqueeze(-1)
                        # Assume data is already cleaned in pre-processing
                        # val = torch.nan_to_num(val, nan=0.0, posinf=0.0, neginf=0.0)
                        seq_dense_value_list.append(val)
                    except IndexError as e:
                        print(
                            f"IndexError seq dense forward: {fc.name}, idx:{current_seq_col_idx}, shape:{X_seq_tensor.shape}"
                        )
                        raise e
                    except Exception as e:
                        print(f"Error seq dense forward: {fc.name}")
                        raise e
        # else: print("æƒ…å ±: X_seq_tensor is empty or None.")

        # --- LSTMå‡¦ç† ---
        if not seq_sparse_embedding_list and not seq_dense_value_list:
            # print("æƒ…å ±: No valid sequence features found for LSTM input.")
            lstm_output_features = torch.zeros((batch_size, self.lstm.hidden_size)).to(
                self.device
            )
        else:
            try:
                lstm_input = torch.cat(
                    seq_sparse_embedding_list + seq_dense_value_list, dim=-1
                )
                # Check if lstm_input size matches expected size
                if lstm_input.shape[-1] != self.lstm.input_size:
                    print(
                        f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: LSTM å…¥åŠ›æ¬¡å…ƒä¸ä¸€è‡´ã€‚æœŸå¾…={self.lstm.input_size}, å®Ÿéš›={lstm_input.shape[-1]}"
                    )
                    # Decide how to handle: raise error or return zeros?
                    raise ValueError(
                        f"LSTM input size mismatch. Expected {self.lstm.input_size}, got {lstm_input.shape[-1]}"
                    )
                    # lstm_output_features = torch.zeros((batch_size, self.lstm.hidden_size)).to(self.device)
                else:
                    lstm_out, (hn, cn) = self.lstm(lstm_input)
                    lstm_output_features = lstm_out[
                        :, -1, :
                    ]  # Use output of last time step
            except Exception as e:
                print(f"Error during LSTM processing forward: {e}")
                # Fallback to zeros
                lstm_output_features = torch.zeros(
                    (batch_size, self.lstm.hidden_size)
                ).to(self.device)

        # --- DCNå…¥åŠ›ã®æº–å‚™ (é™çš„ç‰¹å¾´é‡) ---
        linear_sparse_embedding_list, linear_dense_value_list = [], []
        dnn_sparse_embedding_list, dnn_dense_value_list = [], []

        if X_static_tensor is not None and X_static_tensor.nelement() > 0:
            try:
                # Use the feature_index generated by BaseModel
                linear_sparse_embedding_list, linear_dense_value_list = (
                    self.input_from_feature_columns(
                        X_static_tensor,
                        self.static_linear_feature_columns,
                        self.embedding_dict,
                        self.feature_index,
                    )
                )
                dnn_sparse_embedding_list, dnn_dense_value_list = (
                    self.input_from_feature_columns(
                        X_static_tensor,
                        self.static_dnn_feature_columns,
                        self.embedding_dict,
                        self.feature_index,
                    )
                )
            except Exception as e:
                print(f"Error in input_from_feature_columns forward: {e}")
                # Fallback lists are already empty
        # else: print("æƒ…å ±: X_static_tensor is empty or None.")

        # CrossNetå…¥åŠ›
        cross_input = None
        if self.cross_input_dim > 0:
            if not linear_sparse_embedding_list and not linear_dense_value_list:
                # print("æƒ…å ±: No valid linear features found for CrossNet input.")
                cross_input = torch.zeros((batch_size, self.cross_input_dim)).to(
                    self.device
                )
            else:
                cross_input = combined_dnn_input(
                    linear_sparse_embedding_list, linear_dense_value_list
                )
                # Dimension check for CrossNet input
                if cross_input.shape[1] != self.cross_input_dim:
                    print(
                        f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: CrossNet å…¥åŠ›æ¬¡å…ƒä¸ä¸€è‡´ã€‚æœŸå¾…={self.cross_input_dim}, å®Ÿéš›={cross_input.shape[1]}"
                    )
                    raise ValueError(
                        f"CrossNet input size mismatch. Expected {self.cross_input_dim}, got {cross_input.shape[1]}"
                    )
                    # cross_input = torch.zeros((batch_size, self.cross_input_dim)).to(self.device) # Fallback

        # DNNå…¥åŠ›
        dnn_input_combined = None
        if self.dnn_input_dim > 0:
            if not dnn_sparse_embedding_list and not dnn_dense_value_list:
                # Case where static DNN features are empty, use only LSTM output
                if (
                    lstm_output_features is not None
                    and lstm_output_features.shape[0] == batch_size
                    and lstm_output_features.shape[1] == self.lstm.hidden_size
                ):
                    dnn_input_combined = lstm_output_features
                    # Check if dnn_input_dim was ONLY lstm_hidden_size
                    if self.dnn_input_dim != self.lstm.hidden_size:
                        # This implies static features were expected but missing
                        # print(f"è­¦å‘Š: é™çš„DNNç‰¹å¾´é‡ãŒç©ºã§ã™ãŒã€DNNå…¥åŠ›æ¬¡å…ƒ ({self.dnn_input_dim}) ã¯LSTM ({self.lstm.hidden_size}) ã‚ˆã‚Šå¤§ãã„ã§ã™ã€‚")
                        # Pad static part? Or maybe dnn_input_dim calculation was wrong initially?
                        # Assuming the input should just be LSTM if static is missing here.
                        # If this case is valid, dnn_input_dim should equal lstm_hidden_size.
                        # For now, we proceed, but dimension check later will catch mismatch if dnn_input_dim expects static features.
                        pass
                else:  # No static DNN features AND invalid LSTM output
                    # print("è­¦å‘Š: æœ‰åŠ¹ãªé™çš„DNNç‰¹å¾´é‡ã‚‚LSTMå‡ºåŠ›ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚DNNå…¥åŠ›ã¯ã‚¼ãƒ­ã«ãªã‚Šã¾ã™ã€‚")
                    dnn_input_combined = torch.zeros(
                        (batch_size, self.dnn_input_dim)
                    ).to(self.device)
            else:  # Static DNN features exist
                dnn_input_static = combined_dnn_input(
                    dnn_sparse_embedding_list, dnn_dense_value_list
                )
                if (
                    lstm_output_features is None
                    or lstm_output_features.shape[0] != batch_size
                    or lstm_output_features.shape[1] != self.lstm.hidden_size
                ):
                    # print("è­¦å‘Š: LSTMå‡ºåŠ›ãŒç„¡åŠ¹ã¾ãŸã¯å½¢çŠ¶ä¸ä¸€è‡´ã€‚é™çš„DNNå…¥åŠ›ã®ã¿ã§æ§‹æˆï¼ˆã¾ãŸã¯ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã€‚")
                    # Check if dnn_input_dim expects LSTM output
                    expected_static_dim = self.dnn_input_dim - self.lstm.hidden_size
                    if dnn_input_static.shape[1] == expected_static_dim:
                        # Pad LSTM part with zeros
                        zero_lstm_padding = torch.zeros(
                            (batch_size, self.lstm.hidden_size)
                        ).to(self.device)
                        dnn_input_combined = torch.cat(
                            [dnn_input_static, zero_lstm_padding], dim=-1
                        )
                    elif dnn_input_static.shape[1] == self.dnn_input_dim:
                        # Maybe dnn_input_dim didn't include LSTM? Use static only.
                        # print("æƒ…å ±: DNNå…¥åŠ›æ¬¡å…ƒãŒé™çš„ç‰¹å¾´é‡ã®ã¿ã¨ä¸€è‡´ã™ã‚‹ãŸã‚ã€LSTMå‡ºåŠ›ã‚’ç„¡è¦–ã—ã¾ã™ã€‚")
                        dnn_input_combined = dnn_input_static
                    else:
                        print(
                            f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: DNNé™çš„å…¥åŠ›æ¬¡å…ƒ ({dnn_input_static.shape[1]}) ã¨æœŸå¾…å€¤ ({expected_static_dim} or {self.dnn_input_dim}) ãŒä¸ä¸€è‡´ã€‚"
                        )
                        raise ValueError("Static DNN input dimension mismatch.")
                        # dnn_input_combined = torch.zeros((batch_size, self.dnn_input_dim)).to(self.device) # Fallback
                else:  # Both static DNN and LSTM are valid
                    dnn_input_combined = torch.cat(
                        [dnn_input_static, lstm_output_features], dim=-1
                    )

            # Final check for DNN input dimension
            if dnn_input_combined.shape[1] != self.dnn_input_dim:
                print(
                    f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: æœ€çµ‚çš„ãªDNNå…¥åŠ›æ¬¡å…ƒ ({dnn_input_combined.shape[1]}) ãŒæœŸå¾…å€¤ ({self.dnn_input_dim}) ã¨ä¸ä¸€è‡´ã€‚"
                )
                raise ValueError(
                    f"Final DNN input dimension mismatch. Expected {self.dnn_input_dim}, got {dnn_input_combined.shape[1]}"
                )
                # dnn_input_combined = torch.zeros((batch_size, self.dnn_input_dim)).to(self.device) # Fallback

        # --- DNNå±¤ ---
        dnn_logit = None
        if self.dnn_input_dim > 0 and dnn_input_combined is not None:
            try:
                dnn_output = self.dnn(dnn_input_combined)
                dnn_logit = self.dnn_linear(dnn_output)
            except Exception as e:
                print(f"Error during DNN forward pass: {e}")
                dnn_logit = torch.zeros((batch_size, 1)).to(self.device)  # Fallback
        else:
            # print("æƒ…å ±: DNN input is zero or None, DNN part skipped.")
            dnn_logit = torch.zeros((batch_size, 1)).to(
                self.device
            )  # Ensure shape [B, 1]

        # --- CrossNetå±¤ ---
        cross_out = None
        if (
            self.crossnet is not None
            and self.cross_linear is not None
            and cross_input is not None
        ):
            try:
                cross_features = self.crossnet(cross_input)
                cross_out = self.cross_linear(cross_features)
            except Exception as e:
                print(f"Error during CrossNet forward pass: {e}")
                cross_out = torch.zeros_like(dnn_logit)  # Fallback, shape [B, 1]
        else:
            # print("æƒ…å ±: CrossNet is disabled or input is None, CrossNet part skipped.")
            cross_out = torch.zeros_like(dnn_logit)  # Ensure shape [B, 1]

        # --- æœ€çµ‚å‡ºåŠ› ---
        # Ensure both parts have the same shape [B, 1] before adding
        if dnn_logit.shape != cross_out.shape:
            print(
                f"è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: dnn_logit ({dnn_logit.shape}) ã¨ cross_out ({cross_out.shape}) ã®å½¢çŠ¶ãŒä¸ä¸€è‡´ã€‚"
            )
            # Attempt to recover if one is valid? Or just return zeros?
            # Let's prioritize dnn_logit if shapes mismatch, assuming cross might be zero fallback
            final_logit = (
                dnn_logit
                if dnn_logit.shape[1] == 1
                else torch.zeros((batch_size, 1)).to(self.device)
            )
        else:
            final_logit = cross_out + dnn_logit

        y_pred = self.out(
            final_logit
        )  # self.out is defined in BaseModel for regression/binary
        # Ensure output is clean
        y_pred = torch.nan_to_num(y_pred, nan=0.0, posinf=0.0, neginf=0.0)

        return y_pred


# === LSTM Hybrid ãƒ¢ãƒ‡ãƒ«ã‚¯ãƒ©ã‚¹å®šç¾© (ã“ã“ã¾ã§) ===


# --- äºˆæ¸¬é–¢æ•° (å¤‰æ›´ãªã—) ---
def predict_and_evaluate(model, data_loader, device):
    model.eval()
    predictions = []
    with torch.no_grad():
        for seq_batch, static_batch, _ in tqdm(
            data_loader, desc="äºˆæ¸¬ä¸­"
        ):  # ãƒ©ãƒ™ãƒ«ã¯äºˆæ¸¬ã«ä¸è¦
            seq_batch = seq_batch.to(device)
            static_batch = static_batch.to(device)
            y_pred = model(seq_batch, static_batch).squeeze(-1)  # ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ä¿®æ­£
            predictions.extend(y_pred.cpu().numpy())
    return predictions


# --- å›åç‡è¨ˆç®—é–¢æ•° (è¤‡å‹ç”¨ã«ä¿®æ­£) ---
def calculate_roi(
    df_results,
    bet_type,  # <-- â˜… è¿½åŠ : "å˜å‹" or "è¤‡å‹"
    pred_col="prediction",
    odds_col=None,  # <-- â˜… å¤‰æ›´: å¼•æ•°ã§æŒ‡å®š
    win_flag_col=None,  # <-- â˜… å¤‰æ›´: å¼•æ•°ã§æŒ‡å®š
    top_n=1,
):
    """
    ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«äºˆæ¸¬ã‚¹ã‚³ã‚¢ä¸Šä½Né ­ã‚’é¸æŠã—ã€æŒ‡å®šã•ã‚ŒãŸåˆ¸ç¨®ã®å›åç‡ã¨çš„ä¸­ãƒ¬ãƒ¼ã‚¹ç‡ã‚’è¨ˆç®—ã™ã‚‹ã€‚
    """
    if odds_col is None or win_flag_col is None:
        print(
            f"ã‚¨ãƒ©ãƒ¼({bet_type}): odds_col ã¾ãŸã¯ win_flag_col ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
        )
        return {
            "investment": 0,
            "payout": 0,
            "roi": 0,
            "accuracy": 0,
            "total_races": 0,
            "correct_races": 0,
            "avg_odds": 0,
            "median_odds": 0,
        }

    investment = 0
    payout = 0
    correct_races = 0
    total_races = df_results[RACE_ID_COL].nunique()
    hit_odds = []  # çš„ä¸­æ™‚ã®ã‚ªãƒƒã‚ºã‚’è¨˜éŒ²

    # NaNäºˆæ¸¬ã‚’é™¤å¤–ã—ã¦ã‹ã‚‰ãƒ©ãƒ³ã‚¯ä»˜ã‘
    df_results_filtered = df_results.dropna(
        subset=[pred_col, odds_col, win_flag_col]
    )  # â˜… odds_col, win_flag_col ã‚‚ãƒã‚§ãƒƒã‚¯
    df_results_filtered["pred_rank_in_race"] = df_results_filtered.groupby(RACE_ID_COL)[
        pred_col
    ].rank(method="first", ascending=False)
    selected_horses = df_results_filtered[
        df_results_filtered["pred_rank_in_race"] <= top_n
    ]

    # æŠ•è³‡é¡ã¯é¸ã‚“ã é¦¬ã®æ•° (1é ­100å††)
    investment = len(selected_horses) * 100

    # â–¼â–¼â–¼ã€ä¿®æ­£ã€‘çš„ä¸­åˆ¤å®šã¨æ‰•æˆ»è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ¸ç¨®ã«å¿œã˜ã¦å¤‰æ›´ â–¼â–¼â–¼
    if bet_type == "å˜å‹":
        # win_flag_col (å˜å‹) ãŒ 1 ã®é¦¬ãŒçš„ä¸­
        correct_bets = selected_horses[selected_horses[win_flag_col] == 1]
        # æ‰•æˆ»é‡‘ = 100å†† * ã‚ªãƒƒã‚º (odds_col = å˜å‹ã‚ªãƒƒã‚º)
        payout = (correct_bets[odds_col] * 100).sum()
        hit_odds.extend(correct_bets[odds_col].tolist())
        print(
            f"æƒ…å ±({bet_type}): çš„ä¸­åˆ¤å®šã«åˆ— '{win_flag_col} == 1'ã€æ‰•æˆ»ã«åˆ— '{odds_col}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
        )

    elif bet_type == "è¤‡å‹":
        # win_flag_col (è¤‡å‹åœå†…_å®Ÿ) ãŒ 0 ã‚ˆã‚Šå¤§ãã„é¦¬ (é…å½“é‡‘ãŒã‚ã‚‹é¦¬) ãŒçš„ä¸­
        correct_bets = selected_horses[selected_horses[win_flag_col] > 0]
        # æ‰•æˆ»é‡‘ = é…å½“é‡‘ (odds_col = è¤‡å‹åœå†…_å®Ÿ) â€»100å††ã‚ãŸã‚Šã®å€¤
        payout = correct_bets[odds_col].sum()
        # è¤‡å‹é…å½“é‡‘ã‚’100ã§å‰²ã£ã¦ã‚ªãƒƒã‚ºç›¸å½“ã«å¤‰æ›ã—ã¦è¨˜éŒ² (åˆ†æç”¨)
        hit_odds.extend((correct_bets[odds_col] / 100.0).tolist())
        print(
            f"æƒ…å ±({bet_type}): çš„ä¸­åˆ¤å®šã«åˆ— '{win_flag_col} > 0'ã€æ‰•æˆ»ã«åˆ— '{odds_col}' ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
        )

    else:
        print(f"ã‚¨ãƒ©ãƒ¼({bet_type}): æœªçŸ¥ã®åˆ¸ç¨®ã§ã™ã€‚")
        correct_bets = pd.DataFrame()  # ç©ºã«ã™ã‚‹
    # â–²â–²â–²ã€ä¿®æ­£ã“ã“ã¾ã§ã€‘â–²â–²â–²

    # çš„ä¸­ã—ãŸãƒ¬ãƒ¼ã‚¹æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    correct_races = correct_bets[RACE_ID_COL].nunique()

    roi = (payout / investment * 100) if investment > 0 else 0
    accuracy = (correct_races / total_races * 100) if total_races > 0 else 0
    avg_odds = np.mean(hit_odds) if hit_odds else 0
    median_odds = np.median(hit_odds) if hit_odds else 0

    return {
        "investment": investment,
        "payout": payout,
        "roi": roi,
        "accuracy": accuracy,
        "total_races": total_races,
        "correct_races": correct_races,
        "avg_odds": avg_odds,  # â˜… è¿½åŠ : å¹³å‡çš„ä¸­ã‚ªãƒƒã‚º
        "median_odds": median_odds,  # â˜… è¿½åŠ : çš„ä¸­ã‚ªãƒƒã‚ºä¸­å¤®å€¤
    }


# --- ãƒ¡ã‚¤ãƒ³é–¢æ•° ---
def main():
    print("--- LSTM Hybrid ãƒ¢ãƒ‡ãƒ« è©•ä¾¡ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’é–‹å§‹ ---")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}")

    # --- å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ (.npz) ã®ãƒ­ãƒ¼ãƒ‰ ---
    print(f"--- äº‹å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ ({PREPROCESSED_DATA_PATH}) ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­ ---")
    try:
        data = np.load(PREPROCESSED_DATA_PATH, allow_pickle=True)
        X_seq = data["X_seq"]
        X_static = data["X_static"]
        y = data["y"]

        # â–¼â–¼â–¼ã€ä¿®æ­£ã€‘META_COLS_FOR_EVAL ãƒªã‚¹ãƒˆã‚’ä½¿ã£ã¦ä¸€æ‹¬ãƒ­ãƒ¼ãƒ‰ â–¼â–¼â–¼
        meta_data_dict = {}
        missing_meta_cols = []
        for col in META_COLS_FOR_EVAL:
            if col in data:
                meta_data_dict[col] = data[col]
            else:
                missing_meta_cols.append(col)

        if missing_meta_cols:
            print(
                f"è­¦å‘Š: å¿…è¦ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—ãŒ .npz ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_meta_cols}"
            )
            print(
                "  preprocess_sequences.py ã® META_COLS_FOR_EVAL ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )
            print("  ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„åˆ—ã¯ç„¡è¦–ã—ã¦ç¶šè¡Œã—ã¾ã™ï¼‰")
        # â–²â–²â–²ã€ä¿®æ­£ã“ã“ã¾ã§ã€‘â–²â–²â–²

        df_meta = pd.DataFrame(meta_data_dict)
        # ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ
        static_feature_names_ordered = data["static_feature_names_ordered"].tolist()
        sequence_feature_names_ordered = data["sequence_feature_names_ordered"].tolist()

        print("äº‹å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        print(f"  X_seq shape: {X_seq.shape}")
        print(f"  X_static shape: {X_static.shape}")
        print(f"  y shape: {y.shape}")
        print(f"  Metadata shape: {df_meta.shape}")
        print(f"  Loaded {len(static_feature_names_ordered)} static feature names")
        print(f"  Loaded {len(sequence_feature_names_ordered)} sequence feature names")

        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’Tensorã«å¤‰æ›
        X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)
        X_static_tensor = torch.tensor(X_static, dtype=torch.float32)
        y_tensor = torch.tensor(y, dtype=torch.float32)

        del data, X_seq, X_static, y  # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        gc.collect()

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: äº‹å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ (.npz) ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # --- ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã¨ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¿…è¦ãªæƒ…å ±ã‚’ãƒ­ãƒ¼ãƒ‰ ---
    print(f"--- ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ç­‰ã‚’ '{PREPROCESSOR_BASE_DIR}' ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ä¸­ ---")
    try:
        with open(
            os.path.join(PREPROCESSOR_BASE_DIR, "categorical_mappings.json"),
            "r",
            encoding="utf-8",
        ) as f:
            all_mappings = json.load(f)
        # sequence_feature_names = joblib.load(os.path.join(PREPROCESSOR_BASE_DIR, "sequence_feature_names.pkl")) # npzã‹ã‚‰ãƒ­ãƒ¼ãƒ‰æ¸ˆ
        # static_feature_names = joblib.load(os.path.join(PREPROCESSOR_BASE_DIR, "static_feature_names.pkl")) # npzã‹ã‚‰ãƒ­ãƒ¼ãƒ‰æ¸ˆ
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # --- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡å®šç¾©ã®ãƒ­ãƒ¼ãƒ‰ ---
    print(f"--- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ '{MODEL_OUTPUT_DIR}' ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ä¸­ ---")
    try:
        model_path = os.path.join(MODEL_OUTPUT_DIR, "lstm_hybrid_model.pth")
        # feature_columns.pkl ã¯ä½¿ã‚ãšã€npzã®ãƒªã‚¹ãƒˆã¨ãƒãƒƒãƒ”ãƒ³ã‚°ã‹ã‚‰å†æ§‹ç¯‰
        feature_columns = joblib.load(
            os.path.join(MODEL_OUTPUT_DIR, "feature_columns.pkl")
        )  # ãƒ­ãƒ¼ãƒ‰ã—ã¦æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã«ä½¿ã†

        # --- ç‰¹å¾´é‡ãƒªã‚¹ãƒˆã®å†æ§‹ç¯‰ (ãƒ¢ãƒ‡ãƒ«å®šç¾©ã®ãŸã‚) ---
        # npzã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ãŸé †åºä»˜ããƒªã‚¹ãƒˆã¨ã€ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒãƒƒãƒ”ãƒ³ã‚°æƒ…å ±ã‚’ä½¿ã†
        static_fcs = []
        sequence_fcs = []

        # static_feature_names_ordered ã«åŸºã¥ã static_fcs ã‚’ä½œæˆ
        for name in static_feature_names_ordered:
            if name in all_mappings:  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«
                vocab_size = len(all_mappings[name]) + 1  # 0ã¯æœªçŸ¥ç”¨
                if name == "running_style_id":  # keiba_analysis.py L1155 ã®ãƒ­ã‚¸ãƒƒã‚¯
                    vocab_size = 6
                static_fcs.append(
                    SparseFeat(
                        name, vocabulary_size=vocab_size, embedding_dim=EMBEDDING_DIM
                    )
                )
            else:  # æ•°å€¤ (DenseFeat)
                static_fcs.append(DenseFeat(name, 1))

        # sequence_feature_names_ordered ã«åŸºã¥ã sequence_fcs ã‚’ä½œæˆ
        for name in sequence_feature_names_ordered:
            if name == TARGET_COL:
                continue  # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ—ã¯é™¤å¤–
            if name in all_mappings:  # ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«
                vocab_size = len(all_mappings[name]) + 1
                if name == "running_style_id":  # å¿µã®ãŸã‚
                    vocab_size = 6
                sequence_fcs.append(
                    SparseFeat(
                        name,
                        vocabulary_size=vocab_size,
                        embedding_dim=EMBEDDING_DIM,
                        embedding_name=name,
                    )
                )  # embedding_nameæŒ‡å®š
            else:  # æ•°å€¤ (DenseFeat)
                sequence_fcs.append(DenseFeat(name, 1))

        static_linear_fcs = static_fcs
        static_dnn_fcs = static_fcs

        print(f"å†æ§‹ç¯‰å¾Œã® static_fcs ã®æ•°: {len(static_fcs)}")
        print(f"å†æ§‹ç¯‰å¾Œã® sequence_fcs ã®æ•°: {len(sequence_fcs)}")

        # --- ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ– ---
        model = DCN_LSTM_Hybrid(
            static_linear_feature_columns=static_linear_fcs,
            static_dnn_feature_columns=static_dnn_fcs,
            sequence_feature_columns=sequence_fcs,
            # static_feature_names=static_feature_names_ordered, # ä¸è¦
            lstm_hidden_size=LSTM_HIDDEN_SIZE,
            lstm_layers=LSTM_LAYERS,
            lstm_dropout=LSTM_DROPOUT,
            cross_num=CROSS_NUM,  # <-- â˜… ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã‹ã‚‰å‚ç…§ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ â˜…
            dnn_hidden_units=DNN_HIDDEN_UNITS,
            dnn_use_bn=True,  # <-- â–¼â–¼â–¼ã€ã“ã“ã‚’ False(ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) ã‹ã‚‰ True ã«å¤‰æ›´ã€‘â–¼â–¼â–¼
            task="regression",
            device=device,
            # l2_reg_* ã‚„ init_std ãªã©ã€å­¦ç¿’æ™‚ã¨åŒã˜å€¤ã‚’æŒ‡å®šã—ãŸæ–¹ãŒã‚ˆã‚Šæ­£ç¢ºã§ã™ãŒã€
            # state_dict ã®ãƒ­ãƒ¼ãƒ‰ã ã‘ãªã‚‰å¿…é ˆã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
        ).to(device)

        # ä¿å­˜ã•ã‚ŒãŸé‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
        model.load_state_dict(
            torch.load(model_path, map_location=device, weights_only=True)
        )  # weights_only=True æ¨å¥¨
        print("ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    except RuntimeError as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (RuntimeError): {e}")
        print("ãƒ¢ãƒ‡ãƒ«å®šç¾©ã¨ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®æ§‹é€ ãŒä¸€è‡´ã—ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("ç‰¹ã« LSTM å…¥åŠ›ã‚µã‚¤ã‚ºã€DNN/CrossNet å…¥åŠ›ã‚µã‚¤ã‚ºã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        # Print dimensions for debugging
        try:
            print(f"  ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ LSTM å…¥åŠ›ã‚µã‚¤ã‚º: {model.lstm.input_size}")
            print(f"  ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ DNN å…¥åŠ›ã‚µã‚¤ã‚º: {model.dnn_input_dim}")
            print(f"  ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹ Cross å…¥åŠ›ã‚µã‚¤ã‚º: {model.cross_input_dim}")
        except AttributeError:
            pass  # In case model components are None
        return
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡å®šç¾©ã®ãƒ­ãƒ¼ãƒ‰ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()
        return

    # --- è©•ä¾¡ç”¨ TensorDataset ã¨ DataLoader ä½œæˆ ---
    print("\n--- è©•ä¾¡ç”¨ DataLoader ã‚’ä½œæˆä¸­ ---")
    try:
        eval_tensor_dataset = TensorDataset(X_seq_tensor, X_static_tensor, y_tensor)
        eval_loader = DataLoader(
            eval_tensor_dataset,
            batch_size=BATCH_SIZE,
            shuffle=False,
            num_workers=NUM_WORKERS,
        )
        print("DataLoader ä½œæˆå®Œäº†")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: DataLoader ã®ä½œæˆä¸­ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return

    # --- äºˆæ¸¬å®Ÿè¡Œ ---
    print("\n--- äºˆæ¸¬ã‚’å®Ÿè¡Œ ---")
    predictions = predict_and_evaluate(model, eval_loader, device)

    # --- çµæœã®é›†è¨ˆã¨ä¿å­˜ ---
    print("\n--- äºˆæ¸¬çµæœã‚’é›†è¨ˆä¸­ ---")
    if len(predictions) != len(df_meta):
        print(
            f"ã‚¨ãƒ©ãƒ¼: äºˆæ¸¬çµæœæ•° ({len(predictions)}) ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ•° ({len(df_meta)}) ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚"
        )
        return

    df_meta["prediction"] = predictions

    # çµæœã‚’CSVã«ä¿å­˜
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    output_csv_path = os.path.join(OUTPUT_DIR, "predictions_lstm.csv")
    try:
        # float ã‚’å°æ•°ç‚¹ä»¥ä¸‹4æ¡ã«ä¸¸ã‚ã¦ä¿å­˜
        df_meta_save = df_meta.copy()
        float_cols = df_meta_save.select_dtypes(include=["float"]).columns
        for col in float_cols:
            # prediction ã‚‚ float ã®ã¯ãš
            df_meta_save[col] = df_meta_save[col].round(4)
        df_meta_save.to_csv(output_csv_path, index=False, encoding="utf-8-sig")
        print(f"äºˆæ¸¬çµæœã‚’ {output_csv_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    # --- å›åç‡ã®è¨ˆç®— ---
    print("\n--- å›åç‡ã‚’è¨ˆç®—ä¸­ ---")
    roi_results = {}

    # JSONã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚¯ãƒ©ã‚¹ (tryãƒ–ãƒ­ãƒƒã‚¯ã®å¤–ã§å®šç¾©)
    class NpEncoder(json.JSONEncoder):
        def default(self, obj):
            if isinstance(obj, np.integer):
                return int(obj)
            if isinstance(obj, np.floating):
                if np.isnan(obj) or np.isinf(obj):
                    return None
                return float(obj)
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            return super(NpEncoder, self).default(obj)

    try:
        # --- å˜å‹ã®è¨ˆç®— ---
        win_odds_col = "å˜å‹ã‚ªãƒƒã‚º"
        win_flag_col = "å˜å‹"
        if win_odds_col in df_meta.columns and win_flag_col in df_meta.columns:
            print(f"\n--- [å˜å‹] å›åç‡ ---")
            roi_results["win"] = {}
            for n in [1, 2, 3]:
                result_n = calculate_roi(
                    df_meta,
                    bet_type="å˜å‹",
                    odds_col=win_odds_col,
                    win_flag_col=win_flag_col,
                    top_n=n,
                )
                roi_results["win"][f"top_{n}"] = result_n
                print(f"--- ä¸Šä½ {n} é ­é¸æŠ (å˜å‹) ---")
                print(f"  æŠ•è³‡é‡‘é¡: {result_n['investment']:,.0f} å††")
                print(f"  æ‰•æˆ»é‡‘é¡: {result_n['payout']:,.0f} å††")
                print(f"  å›åç‡ (ROI): {result_n['roi']:.2f}%")
                print(
                    f"  çš„ä¸­ãƒ¬ãƒ¼ã‚¹ç‡: {result_n['accuracy']:.2f}% ({result_n['correct_races']}/{result_n['total_races']} ãƒ¬ãƒ¼ã‚¹)"
                )
                print(f"  å¹³å‡çš„ä¸­ã‚ªãƒƒã‚º: {result_n['avg_odds']:.2f} å€")
        else:
            print(
                f"\nè­¦å‘Š: å˜å‹å›åç‡ã®è¨ˆç®—ã«å¿…è¦ãªåˆ— ({win_odds_col}, {win_flag_col}) ãŒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )

        # --- è¤‡å‹ã®è¨ˆç®— ---
        place_odds_col = ODDS_COL  # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã® "è¤‡å‹åœå†…_å®Ÿ"
        place_flag_col = WIN_FLAG_COL  # ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®šã® "è¤‡å‹åœå†…_å®Ÿ"
        if place_odds_col in df_meta.columns and place_flag_col in df_meta.columns:
            print(f"\n--- [è¤‡å‹] å›åç‡ ---")
            roi_results["place"] = {}
            for n in [1, 2, 3]:
                result_n = calculate_roi(
                    df_meta,
                    bet_type="è¤‡å‹",
                    odds_col=place_odds_col,
                    win_flag_col=place_flag_col,
                    top_n=n,
                )
                roi_results["place"][f"top_{n}"] = result_n
                print(f"--- ä¸Šä½ {n} é ­é¸æŠ (è¤‡å‹) ---")
                print(f"  æŠ•è³‡é‡‘é¡: {result_n['investment']:,.0f} å††")
                print(f"  æ‰•æˆ»é‡‘é¡: {result_n['payout']:,.0f} å††")
                print(f"  å›åç‡ (ROI): {result_n['roi']:.2f}%")
                print(
                    f"  çš„ä¸­ãƒ¬ãƒ¼ã‚¹ç‡: {result_n['accuracy']:.2f}% ({result_n['correct_races']}/{result_n['total_races']} ãƒ¬ãƒ¼ã‚¹)"
                )
                print(f"  å¹³å‡çš„ä¸­ã‚ªãƒƒã‚º (é…å½“é‡‘/100): {result_n['avg_odds']:.2f} å€")
        else:
            print(
                f"\nè­¦å‘Š: è¤‡å‹å›åç‡ã®è¨ˆç®—ã«å¿…è¦ãªåˆ— ({place_odds_col}, {place_flag_col}) ãŒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )

        # å›åç‡çµæœã‚’JSONã«ä¿å­˜
        if roi_results:  # çµæœãŒã‚ã‚Œã°ä¿å­˜
            output_json_path = os.path.join(OUTPUT_DIR, "roi_summary_lstm.json")
            with open(output_json_path, "w", encoding="utf-8") as f:
                json.dump(roi_results, f, ensure_ascii=False, indent=4, cls=NpEncoder)
            print(f"å›åç‡ã‚µãƒãƒªãƒ¼ã‚’ {output_json_path} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")

    except KeyError as e:
        print(f"å›åç‡è¨ˆç®—ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ— '{e}' ãŒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        print(f"åˆ©ç”¨å¯èƒ½ãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ—: {df_meta.columns.tolist()}")
    except Exception as e:
        print(f"å›åç‡è¨ˆç®—ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback

        traceback.print_exc()

    print("\n" + "=" * 50 + "\nğŸ‰ è©•ä¾¡ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå®Œäº†ã—ã¾ã—ãŸ ğŸ‰\n" + "=" * 50)


if __name__ == "__main__":
    main()
